{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf9fd2f",
   "metadata": {},
   "source": [
    "# Assignment: Probability, Bayesian Probability, and Gradient Descent\n",
    "_Group 6_\n",
    "\n",
    "### Group Members\n",
    "- David Akintayo: Probability Distributions  \n",
    "- Cynthia Mutie: Bayesian Probability  \n",
    "- Sougnabe Payang: Manual Gradient Descent  \n",
    "- Elvis Kayonga: Linear Regression with SciPy \n",
    "\n",
    "## Part 0 — Data Setup\n",
    "Load and explore the dataset to be used across all sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d9b459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Name the columns so we understand the data\n",
    "col_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
    "\n",
    "# Download the data from the internet and load it\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\",\n",
    "    header=None, names=col_names\n",
    ")\n",
    "\n",
    "# Show the first 5 rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec21c04",
   "metadata": {},
   "source": [
    "## Part 1 — Probability Distributions (David Akintayo)\n",
    "\n",
    "Implement and compare key **probability distributions** using the Iris dataset.  \n",
    "Tasks:\n",
    "- Compute and visualize probability distributions (e.g., Normal, Uniform, Exponential).  \n",
    "- Plot histograms and fit curves for each feature.  \n",
    "- Analyze which distribution best fits each variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9f9873",
   "metadata": {},
   "source": [
    "## Part 2 — Bayesian Probability (Cynthia Mutie)\n",
    "Dataset: IMDb Movie Reviews (50k) — file in repo: `data/IMDB Dataset.csv`\n",
    "\n",
    "Objective: For chosen keywords compute:\n",
    "- Prior: P(Positive)\n",
    "- Likelihood: P(keyword | Positive)\n",
    "- Marginal: P(keyword)\n",
    "- Posterior: P(Positive | keyword)\n",
    "\n",
    "We will compute P(Positive | keyword) using plain Python + pandas only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d568e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset loaded successfully!\n",
      "Number of rows: 50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = r\"../data/IMDB Dataset.csv\"  # go up one folder\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"✅ Dataset loaded successfully!\")\n",
    "print(\"Number of rows:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "372a96a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# clean reviews\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mreview_clean\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mreview\u001b[39m\u001b[33m'\u001b[39m].str.lower()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Chosen keywords\u001b[39;00m\n\u001b[32m      9\u001b[39m positive_keywords = [\u001b[33m'\u001b[39m\u001b[33mgreat\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mexcellent\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mamazing\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwonderful\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#  Compute Bayesian Probabilities \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# clean reviews\n",
    "df['review_clean'] = df['review'].str.lower()\n",
    "\n",
    "# Chosen keywords\n",
    "positive_keywords = ['great', 'excellent', 'amazing', 'wonderful']\n",
    "negative_keywords = ['bad', 'boring', 'awful', 'worst']\n",
    "\n",
    "# Compute prior P(Positive)\n",
    "p_positive = (df['sentiment'] == 'positive').mean()\n",
    "print(\"Prior P(Positive) =\", round(p_positive, 3))\n",
    "\n",
    "results = []\n",
    "\n",
    "# only compute P(Positive | keyword)\n",
    "for word in positive_keywords + negative_keywords:\n",
    "    has_word = df['review_clean'].str.contains(word)\n",
    "    p_word = has_word.mean()  # marginal P(keyword)\n",
    "    p_word_given_pos = df.loc[df['sentiment']=='positive', 'review_clean'].str.contains(word).mean()  # likelihood\n",
    "    posterior = (p_word_given_pos * p_positive) / p_word if p_word > 0 else np.nan  # Bayes\n",
    "    results.append({\n",
    "        'Keyword': word,\n",
    "        'P(Positive)': round(p_positive, 3),\n",
    "        'P(keyword|Positive)': round(p_word_given_pos, 3),\n",
    "        'P(keyword)': round(p_word, 3),\n",
    "        'P(Positive|keyword)': round(posterior, 3)\n",
    "    })\n",
    "\n",
    "pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3089cffa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'positive_keywords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (p_word_given_pos * p_positive) / p_word\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Compute and print nicely\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpositive_keywords\u001b[49m + negative_keywords:\n\u001b[32m      8\u001b[39m     has_word = df[\u001b[33m'\u001b[39m\u001b[33mreview_clean\u001b[39m\u001b[33m'\u001b[39m].str.contains(word)\n\u001b[32m      9\u001b[39m     p_word = has_word.mean()\n",
      "\u001b[31mNameError\u001b[39m: name 'positive_keywords' is not defined"
     ]
    }
   ],
   "source": [
    "# Implement Bayes' Theorem Function\n",
    "def bayes_posterior(p_positive, p_word_given_pos, p_word):\n",
    "    \"\"\"Compute P(Positive|keyword) using Bayes' theorem\"\"\"\n",
    "    return (p_word_given_pos * p_positive) / p_word\n",
    "\n",
    "# Compute and print nicely\n",
    "for word in positive_keywords + negative_keywords:\n",
    "    has_word = df['review_clean'].str.contains(word)\n",
    "    p_word = has_word.mean()\n",
    "    p_word_given_pos = df.loc[df['sentiment'] == 'positive', 'review_clean'].str.contains(word).mean()\n",
    "    posterior = bayes_posterior(p_positive, p_word_given_pos, p_word)\n",
    "    print(f\"{word:10s} → P(Positive|{word}) = {posterior:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9145c261",
   "metadata": {},
   "source": [
    "## Part 3 — Manual Gradient Descent (Sougnabe Payang)\n",
    "\n",
    "Manually calculate the **gradient descent steps** for a simple cost function:  \n",
    "\\[\n",
    "J(m, b) = \\frac{1}{n}\\sum_{i=1}^n (y_i - (mx_i + b))^2\n",
    "\\]\n",
    "Tasks:\n",
    "- Derive partial derivatives of \\(J\\) with respect to \\(m\\) and \\(b\\).  \n",
    "- Implement manual gradient descent using loops.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b500df3d",
   "metadata": {},
   "source": [
    "## Part 4 — Gradient Descent with SciPy (Elvis Kayonga)\n",
    "\n",
    "Use the **SciPy library** to perform linear regression using optimization tools.  \n",
    "Compare manual vs. automatic gradient descent results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d250a7ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac24e254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
